"use strict";(self.webpackChunkdsd_project=self.webpackChunkdsd_project||[]).push([[1044],{4930:(n,r,i)=>{i.r(r),i.d(r,{assets:()=>c,contentTitle:()=>s,default:()=>p,frontMatter:()=>a,metadata:()=>h,toc:()=>l});var t=i(4848),e=i(8453);const a={title:"T\u1ed1i \u01b0u si\xeau tham s\u1ed1 m\xf4 h\xecnh v\u1edbi Hyperband",slug:"2025/04/hyperparameter-tuning-hyperband",description:"Trong b\xe0i vi\u1ebft n\xe0y, ch\xfang ta s\u1ebd t\xecm hi\u1ec3u v\u1ec1 Hyperband - m\u1ed9t ph\u01b0\u01a1ng ph\xe1p hi\u1ec7u qu\u1ea3 \u0111\u1ec3 t\u1ed1i \u01b0u si\xeau tham s\u1ed1 d\u1ef1a tr\xean nguy\xean l\xfd Early Stopping.",authors:"lhduc",tags:["Data Science"],keywords:["data science","hyperparameter tuning","python","ml","si\xeau tham s\u1ed1","machine learning","m\xe1y h\u1ecdc","t\u1ed1i \u01b0u","Hyperband","Early Stopping"],hide_table_of_contents:!1},s="T\u1ed1i \u01b0u si\xeau tham s\u1ed1 m\xf4 h\xecnh v\u1edbi Hyperband",h={permalink:"/blog/2025/04/hyperparameter-tuning-hyperband",source:"@site/blog/2025/04/11/hyperparameter-tuning-hyperband.md",title:"T\u1ed1i \u01b0u si\xeau tham s\u1ed1 m\xf4 h\xecnh v\u1edbi Hyperband",description:"Trong b\xe0i vi\u1ebft n\xe0y, ch\xfang ta s\u1ebd t\xecm hi\u1ec3u v\u1ec1 Hyperband - m\u1ed9t ph\u01b0\u01a1ng ph\xe1p hi\u1ec7u qu\u1ea3 \u0111\u1ec3 t\u1ed1i \u01b0u si\xeau tham s\u1ed1 d\u1ef1a tr\xean nguy\xean l\xfd Early Stopping.",date:"2025-04-11T00:00:00.000Z",formattedDate:"11 th\xe1ng 4, 2025",tags:[{label:"Data Science",permalink:"/blog/tags/data-science"}],readingTime:8.245,hasTruncateMarker:!1,authors:[{name:"L\xea Hu\u1ef3nh \u0110\u1ee9c",title:"Data Scientist",url:"https://www.linkedin.com/in/lhduc94/",imageURL:"https://i.pinimg.com/1200x/94/8c/1d/948c1d9c51227296803919f227eb4cdf.jpg",key:"lhduc"}],frontMatter:{title:"T\u1ed1i \u01b0u si\xeau tham s\u1ed1 m\xf4 h\xecnh v\u1edbi Hyperband",slug:"2025/04/hyperparameter-tuning-hyperband",description:"Trong b\xe0i vi\u1ebft n\xe0y, ch\xfang ta s\u1ebd t\xecm hi\u1ec3u v\u1ec1 Hyperband - m\u1ed9t ph\u01b0\u01a1ng ph\xe1p hi\u1ec7u qu\u1ea3 \u0111\u1ec3 t\u1ed1i \u01b0u si\xeau tham s\u1ed1 d\u1ef1a tr\xean nguy\xean l\xfd Early Stopping.",authors:"lhduc",tags:["Data Science"],keywords:["data science","hyperparameter tuning","python","ml","si\xeau tham s\u1ed1","machine learning","m\xe1y h\u1ecdc","t\u1ed1i \u01b0u","Hyperband","Early Stopping"],hide_table_of_contents:!1},unlisted:!1,nextItem:{title:"T\u1ed1i \u01b0u si\xeau tham s\u1ed1 m\xf4 h\xecnh v\u1edbi RandomizedSearchCV",permalink:"/blog/2025/03/hyperparameter-tuning-RandomizedSearchCV"}},c={authorsImageUrls:[void 0]},l=[{value:"Gi\u1edbi thi\u1ec7u",id:"gi\u1edbi-thi\u1ec7u",level:2},{value:"Hyperband l\xe0 g\xec?",id:"hyperband-l\xe0-g\xec",level:2},{value:"C\xe1ch ho\u1ea1t \u0111\u1ed9ng c\u1ee7a Hyperband",id:"c\xe1ch-ho\u1ea1t-\u0111\u1ed9ng-c\u1ee7a-hyperband",level:2},{value:"1. Successive Halving (SH)",id:"1-successive-halving-sh",level:3},{value:"2. Hyperband",id:"2-hyperband",level:3},{value:"Tri\u1ec3n khai Hyperband",id:"tri\u1ec3n-khai-hyperband",level:2},{value:"Tri\u1ec3n khai t\u1eeb \u0111\u1ea7u",id:"tri\u1ec3n-khai-t\u1eeb-\u0111\u1ea7u",level:3},{value:"S\u1eed d\u1ee5ng Hyperband v\u1edbi LightGBM",id:"s\u1eed-d\u1ee5ng-hyperband-v\u1edbi-lightgbm",level:3},{value:"So s\xe1nh v\u1edbi c\xe1c ph\u01b0\u01a1ng ph\xe1p kh\xe1c",id:"so-s\xe1nh-v\u1edbi-c\xe1c-ph\u01b0\u01a1ng-ph\xe1p-kh\xe1c",level:2},{value:"K\u1ebft lu\u1eadn",id:"k\u1ebft-lu\u1eadn",level:2}];function m(n){const r={code:"code",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,e.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.h2,{id:"gi\u1edbi-thi\u1ec7u",children:"Gi\u1edbi thi\u1ec7u"}),"\n",(0,t.jsx)(r.p,{children:"Trong b\xe0i vi\u1ebft tr\u01b0\u1edbc, ch\xfang ta \u0111\xe3 t\xecm hi\u1ec3u v\u1ec1 RandomizedSearchCV - m\u1ed9t ph\u01b0\u01a1ng ph\xe1p t\u1ed1i \u01b0u si\xeau tham s\u1ed1 hi\u1ec7u qu\u1ea3 b\u1eb1ng c\xe1ch l\u1ea5y m\u1eabu ng\u1eabu nhi\xean t\u1eeb kh\xf4ng gian tham s\u1ed1. Tuy nhi\xean, ph\u01b0\u01a1ng ph\xe1p n\xe0y v\u1eabn c\xf3 m\u1ed9t h\u1ea1n ch\u1ebf: n\xf3 ph\u1ea3i ch\u1ea1y to\xe0n b\u1ed9 qu\xe1 tr\xecnh hu\u1ea5n luy\u1ec7n cho m\u1ed7i b\u1ed9 tham s\u1ed1 \u0111\u01b0\u1ee3c ch\u1ecdn, ngay c\u1ea3 khi ch\xfang ta c\xf3 th\u1ec3 d\u1ef1 \u0111o\xe1n s\u1edbm r\u1eb1ng m\u1ed9t s\u1ed1 b\u1ed9 tham s\u1ed1 s\u1ebd kh\xf4ng cho k\u1ebft qu\u1ea3 t\u1ed1t."}),"\n",(0,t.jsx)(r.p,{children:"Trong b\xe0i vi\u1ebft n\xe0y, ch\xfang ta s\u1ebd t\xecm hi\u1ec3u v\u1ec1 Hyperband - m\u1ed9t ph\u01b0\u01a1ng ph\xe1p t\u1ed1i \u01b0u si\xeau tham s\u1ed1 th\xf4ng minh h\u01a1n, k\u1ebft h\u1ee3p gi\u1eefa Randomized Search v\xe0 Early Stopping \u0111\u1ec3 lo\u1ea1i b\u1ecf c\xe1c b\u1ed9 tham s\u1ed1 kh\xf4ng tri\u1ec3n v\u1ecdng s\u1edbm h\u01a1n, t\u1eeb \u0111\xf3 ti\u1ebft ki\u1ec7m th\u1eddi gian v\xe0 t\xe0i nguy\xean t\xednh to\xe1n."}),"\n",(0,t.jsx)(r.h2,{id:"hyperband-l\xe0-g\xec",children:"Hyperband l\xe0 g\xec?"}),"\n",(0,t.jsx)(r.p,{children:"Hyperband l\xe0 m\u1ed9t thu\u1eadt to\xe1n t\u1ed1i \u01b0u si\xeau tham s\u1ed1 \u0111\u01b0\u1ee3c ph\xe1t tri\u1ec3n b\u1edfi Li v\xe0 c\u1ed9ng s\u1ef1 v\xe0o n\u0103m 2017. N\xf3 k\u1ebft h\u1ee3p hai \xfd t\u01b0\u1edfng ch\xednh:"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Randomized Search"}),": L\u1ea5y m\u1eabu ng\u1eabu nhi\xean c\xe1c b\u1ed9 tham s\u1ed1 t\u1eeb kh\xf4ng gian t\xecm ki\u1ebfm"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Early Stopping"}),": D\u1eebng s\u1edbm vi\u1ec7c hu\u1ea5n luy\u1ec7n c\xe1c b\u1ed9 tham s\u1ed1 kh\xf4ng tri\u1ec3n v\u1ecdng"]}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:(0,t.jsx)(r.strong,{children:"T\u1ea1i sao n\xean s\u1eed d\u1ee5ng Hyperband?"})}),"\n",(0,t.jsx)(r.p,{children:"So v\u1edbi RandomizedSearchCV, Hyperband mang l\u1ea1i nhi\u1ec1u l\u1ee3i \xedch:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Ti\u1ebft ki\u1ec7m th\u1eddi gian"}),": B\u1eb1ng c\xe1ch d\u1eebng s\u1edbm c\xe1c th\u1eed nghi\u1ec7m kh\xf4ng tri\u1ec3n v\u1ecdng, Hyperband c\xf3 th\u1ec3 ti\u1ebft ki\u1ec7m \u0111\xe1ng k\u1ec3 th\u1eddi gian t\xednh to\xe1n"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Hi\u1ec7u qu\u1ea3 h\u01a1n"}),": V\u1edbi c\xf9ng m\u1ed9t ng\xe2n s\xe1ch th\u1eddi gian, Hyperband c\xf3 th\u1ec3 th\u1eed nhi\u1ec1u b\u1ed9 tham s\u1ed1 h\u01a1n"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Th\xedch \u1ee9ng"}),": T\u1ef1 \u0111\u1ed9ng \u0111i\u1ec1u ch\u1ec9nh s\u1ed1 l\u01b0\u1ee3ng t\xe0i nguy\xean d\xe0nh cho m\u1ed7i b\u1ed9 tham s\u1ed1 d\u1ef1a tr\xean hi\u1ec7u su\u1ea5t ban \u0111\u1ea7u"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"c\xe1ch-ho\u1ea1t-\u0111\u1ed9ng-c\u1ee7a-hyperband",children:"C\xe1ch ho\u1ea1t \u0111\u1ed9ng c\u1ee7a Hyperband"}),"\n",(0,t.jsx)(r.p,{children:"Hyperband ho\u1ea1t \u0111\u1ed9ng th\xf4ng qua m\u1ed9t quy tr\xecnh l\u1eb7p l\u1ea1i g\u1ed3m hai giai \u0111o\u1ea1n ch\xednh:"}),"\n",(0,t.jsx)(r.h3,{id:"1-successive-halving-sh",children:"1. Successive Halving (SH)"}),"\n",(0,t.jsx)(r.p,{children:"Successive Halving l\xe0 c\u1ed1t l\xf5i c\u1ee7a Hyperband. N\xf3 ho\u1ea1t \u0111\u1ed9ng nh\u01b0 sau:"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsx)(r.li,{children:"B\u1eaft \u0111\u1ea7u v\u1edbi n b\u1ed9 tham s\u1ed1 ng\u1eabu nhi\xean"}),"\n",(0,t.jsx)(r.li,{children:"Hu\u1ea5n luy\u1ec7n m\u1ed7i b\u1ed9 tham s\u1ed1 trong m\u1ed9t kho\u1ea3ng th\u1eddi gian ng\u1eafn"}),"\n",(0,t.jsx)(r.li,{children:"Ch\u1ecdn m\u1ed9t n\u1eeda s\u1ed1 b\u1ed9 tham s\u1ed1 c\xf3 hi\u1ec7u su\u1ea5t t\u1ed1t nh\u1ea5t"}),"\n",(0,t.jsx)(r.li,{children:"Ti\u1ebfp t\u1ee5c hu\u1ea5n luy\u1ec7n c\xe1c b\u1ed9 tham s\u1ed1 \u0111\u01b0\u1ee3c ch\u1ecdn v\u1edbi th\u1eddi gian d\xe0i h\u01a1n"}),"\n",(0,t.jsx)(r.li,{children:"L\u1eb7p l\u1ea1i qu\xe1 tr\xecnh cho \u0111\u1ebfn khi ch\u1ec9 c\xf2n m\u1ed9t b\u1ed9 tham s\u1ed1"}),"\n"]}),"\n",(0,t.jsx)(r.h3,{id:"2-hyperband",children:"2. Hyperband"}),"\n",(0,t.jsx)(r.p,{children:"Hyperband m\u1edf r\u1ed9ng Successive Halving b\u1eb1ng c\xe1ch:"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsx)(r.li,{children:"Th\u1eed nhi\u1ec1u c\u1ea5u h\xecnh kh\xe1c nhau c\u1ee7a SH (v\u1edbi c\xe1c gi\xe1 tr\u1ecb n kh\xe1c nhau)"}),"\n",(0,t.jsx)(r.li,{children:"T\u1ef1 \u0111\u1ed9ng \u0111i\u1ec1u ch\u1ec9nh ng\xe2n s\xe1ch th\u1eddi gian cho m\u1ed7i c\u1ea5u h\xecnh"}),"\n",(0,t.jsx)(r.li,{children:"Ch\u1ecdn c\u1ea5u h\xecnh t\u1ed1t nh\u1ea5t d\u1ef1a tr\xean k\u1ebft qu\u1ea3"}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"tri\u1ec3n-khai-hyperband",children:"Tri\u1ec3n khai Hyperband"}),"\n",(0,t.jsxs)(r.p,{children:["Ch\xfang ta s\u1ebd tri\u1ec3n khai Hyperband t\u1eeb \u0111\u1ea7u \u0111\u1ec3 hi\u1ec3u r\xf5 c\xe1ch ho\u1ea1t \u0111\u1ed9ng c\u1ee7a n\xf3. Sau \u0111\xf3, ch\xfang ta s\u1ebd s\u1eed d\u1ee5ng th\u01b0 vi\u1ec7n ",(0,t.jsx)(r.code,{children:"scikit-optimize"})," \u0111\u1ec3 c\xf3 m\u1ed9t tri\u1ec3n khai ho\xe0n ch\u1ec9nh h\u01a1n."]}),"\n",(0,t.jsx)(r.h3,{id:"tri\u1ec3n-khai-t\u1eeb-\u0111\u1ea7u",children:"Tri\u1ec3n khai t\u1eeb \u0111\u1ea7u"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:"import numpy as np\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nfrom sklearn.metrics import accuracy_score, f1_score\r\nimport pandas as pd\r\n\r\n# T\u1ea3i d\u1eef li\u1ec7u\r\nfrom ucimlrepo import fetch_ucirepo\r\nphishing_websites = fetch_ucirepo(id=327)\r\nX = phishing_websites.data.features\r\ny = phishing_websites.data.targets\r\n\r\n# Chia t\u1eadp train v\xe0 test\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"})}),"\n",(0,t.jsx)(r.p,{children:"\u0110\u1ecbnh ngh\u0129a class Hyperband:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:'class Hyperband:\r\n    def __init__(self, estimator, param_distributions, max_iter=81, eta=3, random_state=None):\r\n        self.estimator = estimator\r\n        self.param_distributions = param_distributions\r\n        self.max_iter = max_iter  # S\u1ed1 l\u1ea7n l\u1eb7p t\u1ed1i \u0111a\r\n        self.eta = eta  # H\u1ec7 s\u1ed1 gi\u1ea3m\r\n        self.random_state = random_state\r\n        \r\n        if self.random_state is not None:\r\n            np.random.seed(self.random_state)\r\n            \r\n    def get_hyperband_configs(self):\r\n        """T\xednh to\xe1n c\xe1c c\u1ea5u h\xecnh cho Hyperband\r\n        \r\n        H\xe0m n\xe0y t\xednh to\xe1n c\xe1c c\u1ea5u h\xecnh (n,r) cho m\u1ed7i bracket c\u1ee7a Hyperband, trong \u0111\xf3:\r\n        - n: s\u1ed1 l\u01b0\u1ee3ng c\u1ea5u h\xecnh ban \u0111\u1ea7u c\u1ea7n th\u1eed nghi\u1ec7m\r\n        - r: s\u1ed1 l\u01b0\u1ee3ng t\xe0i nguy\xean \u0111\u01b0\u1ee3c ph\xe2n b\u1ed5 cho m\u1ed7i c\u1ea5u h\xecnh\r\n        \r\n        C\xf4ng th\u1ee9c t\xednh:\r\n        - s_max = \u230alog_\u03b7(max_iter)\u230b\r\n        - B = (s_max + 1) * max_iter\r\n        - V\u1edbi m\u1ed7i s t\u1eeb s_max \u0111\u1ebfn 0:\r\n            + n = \u2308(B/max_iter) * \u03b7^s/(s+1)\u2309\r\n            + r = max_iter * \u03b7^(-s)\r\n        \r\n        Returns:\r\n            list: Danh s\xe1ch c\xe1c tuple (n,r) cho m\u1ed7i bracket c\u1ee7a Hyperband.\r\n                  M\u1ed7i tuple ch\u1ee9a:\r\n                  - n: s\u1ed1 l\u01b0\u1ee3ng c\u1ea5u h\xecnh c\u1ea7n th\u1eed\r\n                  - r: s\u1ed1 l\u01b0\u1ee3ng t\xe0i nguy\xean cho m\u1ed7i c\u1ea5u h\xecnh\r\n        \r\n        Example:\r\n            >>> hb = Hyperband(...)\r\n            >>> configs = hb.get_hyperband_configs()\r\n            >>> print(configs)\r\n            [(81, 1), (27, 3), (9, 9), (6, 27), (5, 81)]  # V\xed d\u1ee5 v\u1edbi max_iter=81, eta=3\r\n        """\r\n        s_max = int(np.log(self.max_iter) / np.log(self.eta))\r\n        B = (s_max + 1) * self.max_iter\r\n        \r\n        configs = []\r\n        for s in range(s_max, -1, -1):\r\n            n = int(np.ceil(B / self.max_iter * (self.eta ** s) / (s + 1)))\r\n            r = self.max_iter * (self.eta ** (-s))\r\n            configs.append((n, r))\r\n            \r\n        return configs\r\n    \r\n    def sample_params(self):\r\n            """\r\n        L\u1ea5y m\u1eabu tham s\u1ed1 t\u1eeb c\xe1c ph\xe2n ph\u1ed1i ho\u1eb7c danh s\xe1ch gi\xe1 tr\u1ecb.\r\n        H\u1ed7 tr\u1ee3:\r\n            - scipy.stats distributions (randint, uniform,...)\r\n            - list gi\xe1 tr\u1ecb r\u1eddi r\u1ea1c\r\n        """\r\n        sampled_params = {}\r\n        for param, dist in self.param_distributions.items():\r\n            if isinstance(dist, (rv_continuous, rv_discrete)):\r\n                sampled_params[param] = dist.rvs()\r\n            elif isinstance(dist, list):\r\n                sampled_params[param] = np.random.choice(dist)\r\n            else:\r\n                raise ValueError(f"Kh\xf4ng h\u1ed7 tr\u1ee3 lo\u1ea1i ph\xe2n ph\u1ed1i: {param}: {type(dist)}")\r\n        return sampled_params\r\n    \r\n    def successive_halving(self, n, r):\r\n        """\r\n        Th\u1ef1c hi\u1ec7n Successive Halving v\u1edbi:\r\n        \r\n        Args:\r\n            n: s\u1ed1 l\u01b0\u1ee3ng c\u1ea5u h\xecnh ban \u0111\u1ea7u (s\u1ed1 l\u01b0\u1ee3ng b\u1ed9 si\xeau tham s\u1ed1 \u0111\u01b0\u1ee3c l\u1ea5y m\u1eabu ng\u1eabu nhi\xean)\r\n            r: s\u1ed1 l\u01b0\u1ee3ng t\xe0i nguy\xean t\u1ed1i \u0111a cho m\u1ed7i c\u1ea5u h\xecnh (c\xf3 th\u1ec3 l\xe0 s\u1ed1 epochs ho\u1eb7c k\xedch th\u01b0\u1edbc d\u1eef li\u1ec7u)\r\n        \r\n        Returns:\r\n            tuple: (final_params, final_score) - b\u1ed9 tham s\u1ed1 t\u1ed1t nh\u1ea5t v\xe0 \u0111i\u1ec3m s\u1ed1 t\u01b0\u01a1ng \u1ee9ng\r\n        """\r\n        # L\u1ea5y m\u1eabu n b\u1ed9 tham s\u1ed1\r\n        params_list = [self.sample_params() for _ in range(n)]\r\n        \r\n        # B\u1eaft \u0111\u1ea7u v\u1edbi r_min = r/eta^(log_eta(r)) t\xe0i nguy\xean\r\n        r_k = r / self.eta ** int(np.log(r) / np.log(self.eta))\r\n        n_k = n\r\n        \r\n        remaining_params = params_list\r\n        \r\n        while n_k > 1:  # Ti\u1ebfp t\u1ee5c cho \u0111\u1ebfn khi ch\u1ec9 c\xf2n 1 c\u1ea5u h\xecnh\r\n            # T\xednh k\xedch th\u01b0\u1edbc subset c\u1ee7a d\u1eef li\u1ec7u d\u1ef1a tr\xean r_k\r\n            n_samples = int(min(r_k, len(X_train)))\r\n            indices = np.random.choice(len(X_train), n_samples, replace=False)\r\n            X_subset = X_train.iloc[indices]\r\n            y_subset = y_train.iloc[indices]\r\n            \r\n            # Hu\u1ea5n luy\u1ec7n v\xe0 \u0111\xe1nh gi\xe1 t\u1eebng c\u1ea5u h\xecnh\r\n            scores = []\r\n            for params in remaining_params:\r\n                # \u0110\u1eb7t n_estimators d\u1ef1a tr\xean r_k n\u1ebfu l\xe0 tham s\u1ed1 c\u1ee7a m\xf4 h\xecnh\r\n                if \'n_estimators\' in params:\r\n                    params[\'n_estimators\'] = max(10, int(r_k))\r\n                    \r\n                self.estimator.set_params(**params)\r\n                self.estimator.fit(X_subset, y_subset)\r\n                \r\n                # \u0110\xe1nh gi\xe1 tr\xean validation set\r\n                val_indices = np.random.choice(len(X_train), min(1000, len(X_train)), replace=False)\r\n                X_val = X_train.iloc[val_indices]\r\n                y_val = y_train.iloc[val_indices]\r\n                score = self.estimator.score(X_val, y_val)\r\n                scores.append((params, score))\r\n            \r\n            # S\u1eafp x\u1ebfp v\xe0 ch\u1ecdn top n_k/eta c\u1ea5u h\xecnh\r\n            scores.sort(key=lambda x: x[1], reverse=True)\r\n            n_k = max(1, int(n_k / self.eta))\r\n            remaining_params = [p for p, _ in scores[:n_k]]\r\n            \r\n            # T\u0103ng t\xe0i nguy\xean cho v\xf2ng ti\u1ebfp theo\r\n            r_k *= self.eta\r\n        \r\n        # Hu\u1ea5n luy\u1ec7n l\u1ea1i c\u1ea5u h\xecnh cu\u1ed1i c\xf9ng v\u1edbi to\xe0n b\u1ed9 d\u1eef li\u1ec7u v\xe0 t\xe0i nguy\xean\r\n        final_params = remaining_params[0]\r\n        if \'n_estimators\' in final_params:\r\n            final_params[\'n_estimators\'] = int(r)\r\n        \r\n        self.estimator.set_params(**final_params)\r\n        self.estimator.fit(X_train, y_train)\r\n        final_score = self.estimator.score(X_train, y_train)\r\n        \r\n        return final_params, final_score\r\n    \r\n    def fit(self, X, y):\r\n        """Th\u1ef1c hi\u1ec7n t\u1ed1i \u01b0u h\xf3a si\xeau tham s\u1ed1 v\u1edbi Hyperband"""\r\n        configs = self.get_hyperband_configs()\r\n        best_score = -np.inf\r\n        best_params = None\r\n        \r\n        for n, r in configs:\r\n            params, score = self.successive_halving(n, r)\r\n            if score > best_score:\r\n                best_score = score\r\n                best_params = params\r\n                \r\n        self.best_params_ = best_params\r\n        self.best_score_ = best_score\r\n        return self\n'})}),"\n",(0,t.jsx)(r.h3,{id:"s\u1eed-d\u1ee5ng-hyperband-v\u1edbi-lightgbm",children:"S\u1eed d\u1ee5ng Hyperband v\u1edbi LightGBM"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:"from scipy.stats import randint, uniform\r\n\r\n# \u0110\u1ecbnh ngh\u0129a kh\xf4ng gian tham s\u1ed1 r\u1ed9ng h\u01a1n cho LightGBM\r\nparam_space = {\r\n    'num_leaves': randint(20, 100),  # S\u1ed1 l\xe1 trong c\xe2y\r\n    'max_depth': randint(3, 12),     # \u0110\u1ed9 s\xe2u t\u1ed1i \u0111a\r\n    'learning_rate': uniform(0.01, 0.3),  # T\u1ed1c \u0111\u1ed9 h\u1ecdc\r\n    'n_estimators': randint(50, 300), # S\u1ed1 c\xe2y\r\n    'min_child_samples': randint(10, 50),  # S\u1ed1 m\u1eabu t\u1ed1i thi\u1ec3u trong m\u1ed7i l\xe1\r\n    'subsample': uniform(0.6, 0.4),   # T\u1ef7 l\u1ec7 m\u1eabu s\u1eed d\u1ee5ng cho m\u1ed7i c\xe2y\r\n    'colsample_bytree': uniform(0.6, 0.4),  # T\u1ef7 l\u1ec7 features s\u1eed d\u1ee5ng cho m\u1ed7i c\xe2y\r\n    'reg_alpha': uniform(0, 1),       # L1 regularization\r\n    'reg_lambda': uniform(0, 1),      # L2 regularization\r\n    'min_child_weight': uniform(0, 1)  # Tr\u1ecdng s\u1ed1 t\u1ed1i thi\u1ec3u cho m\u1ed7i l\xe1\r\n}\r\n\r\n# Kh\u1edfi t\u1ea1o v\xe0 ch\u1ea1y Hyperband\r\nhb = Hyperband(\r\n    estimator=lgb.LGBMClassifier(random_state=42),\r\n    param_space=param_space,\r\n    max_iter=81,\r\n    eta=3,\r\n    random_state=42\r\n)\r\n\r\nhb.fit(X_train, y_train)\r\n\r\nprint(\"Best parameters:\", hb.best_params_)\r\nprint(\"Best score:\", hb.best_score_)\n"})}),"\n",(0,t.jsx)(r.h2,{id:"so-s\xe1nh-v\u1edbi-c\xe1c-ph\u01b0\u01a1ng-ph\xe1p-kh\xe1c",children:"So s\xe1nh v\u1edbi c\xe1c ph\u01b0\u01a1ng ph\xe1p kh\xe1c"}),"\n",(0,t.jsx)(r.p,{children:"H\xe3y so s\xe1nh hi\u1ec7u su\u1ea5t c\u1ee7a Hyperband v\u1edbi RandomizedSearchCV v\xe0 GridSearchCV:"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\r\nimport time\r\n\r\n# RandomizedSearchCV\r\nstart_time = time.time()\r\nrandom_search = RandomizedSearchCV(\r\n    lgb.LGBMClassifier(random_state=42),\r\n    param_distributions=param_space,\r\n    n_iter=50,\r\n    cv=5,\r\n    n_jobs=-1,\r\n    random_state=42,\r\n    scoring='f1'\r\n)\r\nrandom_search.fit(X_train, y_train)\r\nrandom_time = time.time() - start_time\r\n\r\n# GridSearchCV v\u1edbi m\u1ed9t t\u1eadp con c\u1ee7a tham s\u1ed1\r\nparam_grid = {\r\n    'num_leaves': [30, 50, 70],\r\n    'max_depth': [5, 7, 9],\r\n    'learning_rate': [0.01, 0.1, 0.3],\r\n    'n_estimators': [100, 200, 300],\r\n    'subsample': [0.6, 0.8, 1.0],\r\n    'colsample_bytree': [0.6, 0.8, 1.0]\r\n}\r\nstart_time = time.time()\r\ngrid_search = GridSearchCV(\r\n    lgb.LGBMClassifier(random_state=42),\r\n    param_grid,\r\n    cv=5,\r\n    n_jobs=-1,\r\n    scoring='f1'\r\n)\r\ngrid_search.fit(X_train, y_train)\r\ngrid_time = time.time() - start_time\r\n\r\n# Hyperband\r\nstart_time = time.time()\r\nhb = Hyperband(\r\n    estimator=lgb.LGBMClassifier(random_state=42),\r\n    param_space=param_space,\r\n    max_iter=81,\r\n    eta=3,\r\n    random_state=42\r\n)\r\nhb.fit(X_train, y_train)\r\nhyperband_time = time.time() - start_time\r\n\r\n# So s\xe1nh k\u1ebft qu\u1ea3\r\nresults = pd.DataFrame({\r\n    'Method': ['RandomizedSearchCV', 'GridSearchCV', 'Hyperband'],\r\n    'Best F1 Score': [random_search.best_score_, grid_search.best_score_, hb.best_score_],\r\n    'Time (s)': [random_time, grid_time, hyperband_time]\r\n})\r\nprint(results)\r\n\r\n# \u0110\xe1nh gi\xe1 tr\xean t\u1eadp test v\u1edbi m\xf4 h\xecnh t\u1ed1t nh\u1ea5t\r\nbest_model = lgb.LGBMClassifier(**hb.best_params_, random_state=42)\r\nbest_model.fit(X_train, y_train)\r\ny_pred = best_model.predict(X_test)\r\nprint(\"\\nTest F1 Score:\", f1_score(y_test, y_pred))\r\nprint(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n"})}),"\n",(0,t.jsx)(r.h2,{id:"k\u1ebft-lu\u1eadn",children:"K\u1ebft lu\u1eadn"}),"\n",(0,t.jsx)(r.p,{children:"Hyperband l\xe0 m\u1ed9t ph\u01b0\u01a1ng ph\xe1p t\u1ed1i \u01b0u si\xeau tham s\u1ed1 hi\u1ec7u qu\u1ea3, \u0111\u1eb7c bi\u1ec7t ph\xf9 h\u1ee3p khi:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"C\xf3 nhi\u1ec1u tham s\u1ed1 c\u1ea7n t\u1ed1i \u01b0u"}),"\n",(0,t.jsx)(r.li,{children:"Th\u1eddi gian v\xe0 t\xe0i nguy\xean t\xednh to\xe1n h\u1ea1n ch\u1ebf"}),"\n",(0,t.jsx)(r.li,{children:"C\u1ea7n t\u1ef1 \u0111\u1ed9ng \u0111i\u1ec1u ch\u1ec9nh ng\xe2n s\xe1ch th\u1eddi gian cho m\u1ed7i b\u1ed9 tham s\u1ed1"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"Tuy nhi\xean, c\u0169ng nh\u01b0 c\xe1c ph\u01b0\u01a1ng ph\xe1p kh\xe1c, Hyperband kh\xf4ng ph\u1ea3i l\xe0 gi\u1ea3i ph\xe1p ho\xe0n h\u1ea3o cho m\u1ecdi tr\u01b0\u1eddng h\u1ee3p. Vi\u1ec7c l\u1ef1a ch\u1ecdn ph\u01b0\u01a1ng ph\xe1p t\u1ed1i \u01b0u si\xeau tham s\u1ed1 ph\u1ee5 thu\u1ed9c v\xe0o:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"K\xedch th\u01b0\u1edbc v\xe0 \u0111\u1ed9 ph\u1ee9c t\u1ea1p c\u1ee7a d\u1eef li\u1ec7u"}),"\n",(0,t.jsx)(r.li,{children:"S\u1ed1 l\u01b0\u1ee3ng v\xe0 lo\u1ea1i si\xeau tham s\u1ed1 c\u1ea7n t\u1ed1i \u01b0u"}),"\n",(0,t.jsx)(r.li,{children:"T\xe0i nguy\xean t\xednh to\xe1n c\xf3 s\u1eb5n"}),"\n",(0,t.jsx)(r.li,{children:"Y\xeau c\u1ea7u v\u1ec1 \u0111\u1ed9 ch\xednh x\xe1c v\xe0 th\u1eddi gian"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"Trong th\u1ef1c t\u1ebf, vi\u1ec7c k\u1ebft h\u1ee3p nhi\u1ec1u ph\u01b0\u01a1ng ph\xe1p (nh\u01b0 \u0111\xe3 th\u1ea5y trong b\xe0i vi\u1ebft tr\u01b0\u1edbc v\u1ec1 vi\u1ec7c k\u1ebft h\u1ee3p RandomizedSearch v\xe0 GridSearch) th\u01b0\u1eddng mang l\u1ea1i k\u1ebft qu\u1ea3 t\u1ed1t nh\u1ea5t."})]})}function p(n={}){const{wrapper:r}={...(0,e.R)(),...n.components};return r?(0,t.jsx)(r,{...n,children:(0,t.jsx)(m,{...n})}):m(n)}},8453:(n,r,i)=>{i.d(r,{R:()=>s,x:()=>h});var t=i(6540);const e={},a=t.createContext(e);function s(n){const r=t.useContext(a);return t.useMemo((function(){return"function"==typeof n?n(r):{...r,...n}}),[r,n])}function h(n){let r;return r=n.disableParentContext?"function"==typeof n.components?n.components(e):n.components||e:s(n.components),t.createElement(a.Provider,{value:r},n.children)}}}]);