---
title: Tá»‘i Æ°u siÃªu tham sá»‘ mÃ´ hÃ¬nh vá»›i GridSearchCV
slug: 2025/03/hyperparameter-tuning-gridsearchCV
description: Trong huáº¥n luyá»‡n mÃ´ hÃ¬nh mÃ¡y há»c, viá»‡c lá»±a chá»n siÃªu tham sá»‘ (hyperparameters) áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh. KhÃ´ng giá»‘ng nhÆ° tham sá»‘ há»c Ä‘Æ°á»£c tá»« dá»¯ liá»‡u, siÃªu tham sá»‘ cáº§n Ä‘Æ°á»£c thiáº¿t láº­p trÆ°á»›c khi huáº¥n luyá»‡n. 
authors: lhduc
tags: [Data Science]
keywords: [data science, hyperparameter tuning, python, ml, siÃªu tham sá»‘, machine learning, mÃ¡y há»c, tá»‘i Æ°u, gridsearchcv]
image: /img/blog/20250304_1_cover.jpg
hide_table_of_contents: false
draft: false
---
![](cover.jpg)

## Giá»›i thiá»‡u
Trong huáº¥n luyá»‡n mÃ´ hÃ¬nh mÃ¡y há»c, viá»‡c lá»±a chá»n siÃªu tham sá»‘ (hyperparameters) áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n hiá»‡u suáº¥t cá»§a mÃ´ hÃ¬nh. 
KhÃ´ng giá»‘ng nhÆ° tham sá»‘ há»c Ä‘Æ°á»£c tá»« dá»¯ liá»‡u, siÃªu tham sá»‘ cáº§n Ä‘Æ°á»£c thiáº¿t láº­p trÆ°á»›c khi huáº¥n luyá»‡n. 
Hyperparameter Tuning lÃ  quÃ¡ trÃ¬nh tÃ¬m kiáº¿m giÃ¡ trá»‹ tá»‘i Æ°u Ä‘á»ƒ mÃ´ hÃ¬nh hoáº¡t Ä‘á»™ng tá»‘t nháº¥t. 
Viá»‡c nÃ y giÃºp cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c, trÃ¡nh overfitting vÃ  underfitting.

Trong ná»™i dung bÃ i viáº¿t nÃ y, mÃ¬nh sáº½ giá»›i thiá»‡u vá» phÆ°Æ¡ng phÃ¡p cÆ¡ báº£n nháº¥t Ä‘á»ƒ tá»‘i Æ°u siÃªu tham sá»‘ lÃ  GridSearchCV.


## Hyperparameter lÃ  gÃ¬?

Äáº§u tiÃªn, chÃºng ta cáº§n biáº¿t Ä‘á»‹nh nghÄ©a Hyperparamter lÃ  gÃ¬. Theo nghÄ©a tiáº¿ng Viá»‡t thÃ¬ hyperparameter nghÄ©a lÃ  siÃªu tham sá»‘ Ä‘Æ°á»£c cÃ i Ä‘áº·t trÆ°á»›c khi quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh báº¯t Ä‘áº§u. KhÃ¡c vá»›i cÃ¡c parameter thÃ´ng thÆ°á»ng Ä‘Æ°á»£c há»c trong quÃ¡ trÃ¬nh training, hyperparameter cáº§n Ä‘Æ°á»£c thiáº¿t láº­p bá»Ÿi ngÆ°á»i láº­p trÃ¬nh vÃ  áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh.
<figure>
![](hyperparamters.png)
<figcaption>Hyperparameter trong DecisionTreeClassifer</figcaption>
</figure>

Má»™t sá»‘ hyperparameter phá»• biáº¿n:
- Äá»™ sÃ¢u cá»§a cÃ¢y (*max_depth*) trong **DecisionTree**
- Sá»‘ lÆ°á»£ng cÃ¢y `n_estimators` trong **RandomForest**
- Learning rate (*eta*, *learning_rate*) trong Gradient Descent
- Há»‡ sá»‘ regularization nhÆ°  *alpha* trong **Ridge/Lasso**, *C* trong **SVM**
- Sá»‘ lá»›p áº©n (*n_layers*) vÃ  sá»‘ neuron(*hidden_state*) trong máº¡ng neural
- Sá»‘ lÆ°á»£ng dá»¯ liá»‡u trong má»™t batch *batch_size*
- CÃ¡c chá»‰ tiÃªu Ä‘Ã¡nh giÃ¡ nhÆ° *criterion* trong DecisionTree
...

## Táº¡i sao cáº§n Hyperparameter Tuning?

### TrÃ¡nh overfitting vÃ  underfitting

**Overfitting** xáº£y ra khi mÃ´ hÃ¬nh há»c quÃ¡ khá»›p vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n nhÆ°ng khÃ´ng tá»•ng quÃ¡t hÃ³a Ä‘Æ°á»£c vá»›i dá»¯ liá»‡u má»›i. Trong khi **Underfitting** xáº£y ra khi mÃ´ hÃ¬nh quÃ¡ Ä‘Æ¡n giáº£n vÃ  khÃ´ng náº¯m báº¯t Ä‘Æ°á»£c cÃ¡c máº«u trong dá»¯ liá»‡u. Viá»‡c tinh chá»‰nh siÃªu tham sá»‘ giÃºp cÃ¢n báº±ng giá»¯a hai váº¥n Ä‘á» nÃ y, Ä‘áº£m báº£o mÃ´ hÃ¬nh tá»•ng quÃ¡t hÃ³a tá»‘t.

![](overfitting_underfitting.png)

HÃ¬nh trÃªn lÃ  hÃ¬nh minh há»a Decision Tree vá»›i 3 cÃ¡ch lá»±a chá»n siÃªu tham sá»‘ *max_depth*
- *max_depth=1*: Underfitting, mÃ´ hÃ¬nh quÃ¡ Ä‘Æ¡n giáº£n, khÃ´ng báº¯t Ä‘Æ°á»£c xu hÆ°á»›ng dá»¯ liá»‡u.
- *max_depth=10*: Overfitting, mÃ´ hÃ¬nh quÃ¡ phá»©c táº¡p, khá»›p cháº·t vá»›i dá»¯ liá»‡u huáº¥n luyá»‡n nhÆ°ng cÃ³ thá»ƒ tá»•ng quÃ¡t hÃ³a kÃ©m.
- *max_depth=4*: Optimal, mÃ´ hÃ¬nh cÃ¢n báº±ng giá»¯a Ä‘Æ¡n giáº£n vÃ  phá»©c táº¡p, dá»± Ä‘oÃ¡n tá»‘t.

### Tá»‘i Æ°u hÃ³a thá»i gian vÃ  tÃ i nguyÃªn
Má»™t sá»‘ siÃªu tham sá»‘ nhÆ° kÃ­ch thÆ°á»›c batch (batch size) hoáº·c sá»‘ lÆ°á»£ng epoch áº£nh hÆ°á»Ÿng Ä‘áº¿n thá»i gian huáº¥n luyá»‡n vÃ  tÃ i nguyÃªn tÃ­nh toÃ¡n.
Tinh chá»‰nh giÃºp tÃ¬m ra cáº¥u hÃ¬nh tá»‘i Æ°u Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh nhanh hÆ¡n mÃ  khÃ´ng lÃ m giáº£m hiá»‡u suáº¥t.
![](batch_size.png)

ÄÃ¢y lÃ  biá»ƒu Ä‘á»“ minh há»a áº£nh hÆ°á»Ÿng cá»§a kÃ­ch thÆ°á»›c batch (Batch Size) Ä‘áº¿n thá»i gian huáº¥n luyá»‡n vÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh:

- **ÄÆ°á»ng mÃ u Ä‘á»**: Thá»i gian huáº¥n luyá»‡n giáº£m khi Batch Size tÄƒng.
- **ÄÆ°á»ng mÃ u xanh**: Äá»™ chÃ­nh xÃ¡c cá»§a mÃ´ hÃ¬nh tÄƒng Ä‘áº¿n má»™t má»©c tá»‘i Æ°u rá»“i báº¯t Ä‘áº§u giáº£m nháº¹.

Biá»ƒu Ä‘á»“ nÃ y thá»ƒ hiá»‡n ráº±ng viá»‡c tá»‘i Æ°u Batch Size giÃºp giáº£m thá»i gian huáº¥n luyá»‡n mÃ  váº«n duy trÃ¬ hiá»‡u suáº¥t mÃ´ hÃ¬nh tá»‘t.

### Giáº£m chi phÃ­ tÃ­nh toÃ¡n

Náº¿u chÃºng ta chá»n tham sá»‘ khÃ´ng há»£p lÃ½, mÃ´ hÃ¬nh cÃ³ thá»ƒ máº¥t nhiá»u thá»i gian Ä‘á»ƒ há»™i tá»¥, Ä‘iá»u nÃ y dáº«n Ä‘áº¿n tÄƒng chi phÃ­ tÃ­nh toÃ¡n mÃ  khÃ´ng cáº£i thiá»‡n Ä‘Æ°á»£c hiá»‡u suáº¥t mÃ´ hÃ¬nh. 

VÃ­ dá»¥ nhÆ° **grid search**, chÃºng ta cáº§n thá»­ táº¥t cáº£ cÃ¡c tá»• há»£p giÃ¡ trá»‹ trong khÃ´ng gian tÃ¬m kiáº¿m, Ä‘iá»u nÃ y cÃ³ thá»ƒ tá»‘n nhiá»u thá»i gian vÃ  tÃ i nguyÃªn. 

NgÆ°á»£c láº¡i náº¿u dÃ¹ng **random search** hoáº·c **bayesian optimization**, chÃºng ta cÃ³ thá»ƒ giáº£m Ä‘Æ°á»£c sá»‘ láº§n thá»­ nghiá»‡m vÃ  tÃ i nguyÃªn tÃ­nh toÃ¡n. Do Ä‘Ã³, viá»‡c tá»‘i Æ°u siÃªu tham sá»‘ giÃºp tiáº¿t kiá»‡m chi phÃ­ tÃ­nh toÃ¡n.

## CÃ¡c phÆ°Æ¡ng phÃ¡p Hyperparameter Tuning

### Grid Search

Grid search lÃ  phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u siÃªu tham sá»‘ báº±ng cÃ¡ch thá»­ táº¥t cáº£ cÃ¡c tá»• há»£p giÃ¡ trá»‹ trong khÃ´ng gian tÃ¬m kiáº¿m. 
VÃ­ dá»¥ náº¿u báº¡n cÃ³ 2 siÃªu tham sá»‘

- *max_depth* vá»›i cÃ¡c giÃ¡ trá»‹ nguyÃªn trong danh sÃ¡ch [4,5,6]
- *n_estimators* vá»›i cÃ¡c giÃ¡ trá»‹ nguyÃªn trong danh sÃ¡ch [10,20,30]

ThÃ¬ grid search sáº½ thá»­ táº¥t cáº£ cÃ¡c tá»• há»£p giÃ¡ trá»‹ trong khÃ´ng gian tÃ¬m kiáº¿m nhÆ°
- *max_depth=4, n_estimators=10*
- *max_depth=4, n_estimators=20*
- *max_depth=4, n_estimators=30*
- *max_depth=5, n_estimators=10*
- *max_depth=5, n_estimators=20*
- *max_depth=5, n_estimators=30*
- *max_depth=6, n_estimators=10*

Sau Ä‘Ã³ chá»n ra tá»• há»£p cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t.

Æ¯u Ä‘iá»ƒm cá»§a phÆ°Æ¡ng phÃ¡p nÃ y lÃ  Ä‘Æ¡n giáº£n vÃ  dá»… thá»±c hiá»‡n tuy nhiÃªn nhÆ°á»£c Ä‘iá»ƒm lÃ  tá»‘n thá»i gian vá»›i khÃ´ng gian lá»›n. Giáº£ sá»­ chÃºng ta cÃ³ nhiá»u hÆ¡n 2 siÃªu tham sá»‘, vÃ­ dá»¥ 3 siÃªu tham sá»‘, má»—i tham sá»‘ vá»›i 5 giÃ¡ trá»‹ khÃ¡c nhau, thÃ¬ sáº½ cÃ³ 5^3 = 125 tá»• há»£p.

DÆ°á»›i Ä‘Ã¢y lÃ  vÃ­ dá»¥ code python cho Grid Search Ä‘Æ¡n giáº£n. MÃ¬nh sáº½ dÃ¹ng bá»™ dá»¯ liá»‡u [Phishing Websites](https://archive.ics.uci.edu/dataset/327/phishing+websites). Bá»™ dá»¯ liá»‡u nÃ y chá»‰ chá»©a cÃ¡c feature thuá»™c numerical.


**Chuáº©n bá»‹ dá»¯ liá»‡u**
```python
from sklearn.model_selection import train_test_split
from ucimlrepo import fetch_ucirepo 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# fetch dataset 
phishing_websites = fetch_ucirepo(id=327) 
  
# data (as pandas dataframes) 
X = phishing_websites.data.features 
y = phishing_websites.data.targets


# Chia táº­p train vÃ  test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Chia táº­p train vÃ  valid
X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.25, random_state=42, stratify=y_train)

# Kiá»ƒm tra kÃ­ch thÆ°á»›c dá»¯ liá»‡u
print(f"Train size: {X_train.shape}, Valid size: {X_valid.shape}, Test size: {X_test.shape}")
```

<pythonoutput>
```
Train size: (6633, 30), Valid size: (2211, 30), Test size: (2211, 30)
```
</pythonoutput>

**Táº¡o táº¥t cáº£ cÃ¡c tá»• há»£p tham sá»‘ cÃ³ thá»ƒ cÃ³**

```python
import itertools

param_grid = {
    'n_estimators': [50, 100, 200],  
    'max_depth': [3, 5, 10],
}

# Táº¡o táº¥t cáº£ cÃ¡c tá»• há»£p tham sá»‘ cÃ³ thá»ƒ cÃ³
param_combinations = list(itertools.product(*param_grid.values()))
for param in param_combinations:
    print(f'n_estimators: {param[0]}, \t max_depth: {param[1]}')

```

<pythonoutput>
```
n_estimators: 50, 	 max_depth: 3
n_estimators: 50, 	 max_depth: 5
n_estimators: 50, 	 max_depth: 10
n_estimators: 100, 	 max_depth: 3
n_estimators: 100, 	 max_depth: 5
n_estimators: 100, 	 max_depth: 10
n_estimators: 200, 	 max_depth: 3
n_estimators: 200, 	 max_depth: 5
n_estimators: 200, 	 max_depth: 10
```
</pythonoutput>

**Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i tá»«ng tá»• há»£p tham sá»‘**

```python
# LÆ°u káº¿t quáº£
best_score = 0
best_params = None
best_model = None

# Thá»­ tá»«ng bá»™ tham sá»‘
for params in param_combinations:
    param_dict = dict(zip(param_grid.keys(), params))
    
    # Train model
    model = RandomForestClassifier(**param_dict, random_state=42)
    model.fit(X_train, y_train)
    
    # Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
    y_pred = model.predict(X_valid)
    accuracy = accuracy_score(y_valid, y_pred)
    
    # LÆ°u láº¡i bá»™ tham sá»‘ tá»‘t nháº¥t
    if accuracy > best_score:
        best_score = accuracy
        best_params = param_dict
        best_model = model

# In káº¿t quáº£ tá»‘t nháº¥t
print("Best Parameters:", best_params)
print("Best Model Accuracy on Valid Set:", best_score)
```
<pythonoutput>
```
Best Parameters: {'n_estimators': 200, 'max_depth': 10}
Best Model Accuracy on Valid Set: 0.9547715965626413
```
</pythonoutput>

**ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test**

```python
# Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
y_pred = best_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Tuned Model Accuracy on Test Set: {accuracy:.4f}")
```
<pythonoutput>
```
Tuned Model Accuracy on Test Set: 0.9557
```
</pythonoutput>

ChÃºng ta sáº½ so sÃ¡nh vá»›i mÃ´ hÃ¬nh cÆ¡ báº£n

```python
model = RandomForestClassifier( n_estimators=50, max_depth=5, random_state=42)
model.fit(X_train, y_train)
y_pred_valid = model.predict(X_valid)
accuracy = accuracy_score(y_valid, y_pred_valid)
print(f"Model Accuracy on Valid Set: {accuracy:.4f}")
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy on Test Set: {accuracy:.4f}")


```
<pythonoutput>
```
Model Accuracy on Valid Set: 0.9326
Model Accuracy on Test Set: 0.9331
```
</pythonoutput>


### GridSearchCV

GridSearchCV lÃ  phÆ°Æ¡ng phÃ¡p GridSearch sá»­ dá»¥ng tá»‘i Æ°u dá»±a trÃªn Cross Validation thay vÃ¬ chia táº­p dá»¯ liá»‡u thÃ nh train/valid/test nhÆ° thÃ´ng thÆ°á»ng

| TiÃªu chÃ­ | **Grid Search (Thá»§ cÃ´ng)** | **GridSearchCV** |
|----------|------------------|-----------------|
| **CÃ¡ch hoáº¡t Ä‘á»™ng** | Duyá»‡t qua táº¥t cáº£ cÃ¡c tá»• há»£p tham sá»‘  <br/>trÃªn má»™t táº­ptrain/test cá»‘ Ä‘á»‹nh | Duyá»‡t qua táº¥t cáº£ cÃ¡c tá»• há»£p tham sá»‘ <br/>vÃ  sá»­ dá»¥ng Cross-Validation (CV)  Ä‘á»ƒ <br/>Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c trÃªn nhiá»u táº­p con |
| **Cross-Validation (CV)** | âŒ KhÃ´ng dÃ¹ng CV, chá»‰ train/test 1 láº§n | âœ… DÃ¹ng CV (k-fold) Ä‘á»ƒ kiá»ƒm tra Ä‘á»™ á»•n Ä‘á»‹nh |
| **Sá»‘ láº§n train mÃ´ hÃ¬nh** | ğŸ”¹ Báº±ng sá»‘ tá»• há»£p tham sá»‘ thá»­ nghiá»‡m | ğŸ”¹ Báº±ng sá»‘ tá»• há»£p tham sá»‘ * sá»‘ lÆ°á»£ng fold cá»§a CV |
| **Tá»‘c Ä‘á»™** | âš¡ Nhanh hÆ¡n, do chá»‰ train má»™t láº§n má»—i tá»• há»£p | ğŸ¢ Cháº­m hÆ¡n, do train nhiá»u láº§n trÃªn táº­p dá»¯ liá»‡u chia nhá» |
| **Äá»™ tin cáº­y cá»§a mÃ´ hÃ¬nh** | ğŸ“‰ Tháº¥p hÆ¡n, vÃ¬ chá»‰ Ä‘Ã¡nh giÃ¡ trÃªn má»™t táº­p train-test | ğŸ“ˆ Cao hÆ¡n, vÃ¬ Ä‘Ã¡nh giÃ¡ trÃªn nhiá»u táº­p con khÃ¡c nhau |
| **Nguy cÆ¡ overfitting** | âš ï¸ Cao hÆ¡n, do chá»‰ test trÃªn má»™t táº­p dá»¯ liá»‡u | âœ… Giáº£m thiá»ƒu overfitting, vÃ¬ kiá»ƒm tra trÃªn nhiá»u táº­p con |
| **Khi nÃ o nÃªn dÃ¹ng?** | âœ… Khi dá»¯ liá»‡u lá»›n, cáº§n cháº¡y nhanh âš¡ | âœ… Khi muá»‘n mÃ´ hÃ¬nh á»•n Ä‘á»‹nh hÆ¡n, trÃ¡nh phá»¥ thuá»™c vÃ o má»™t táº­p dá»¯ liá»‡u |
| **ThÆ° viá»‡n há»— trá»£** | ğŸ”¹ Tá»± triá»ƒn khai thá»§ cÃ´ng báº±ng Python | ğŸ”¹ CÃ³ sáºµn trong `sklearn.model_selection.GridSearchCV` |

ChÃºng ta nÃªn dÃ¹ng GridSearchCV hÆ¡n lÃ  grid search thá»§ cÃ´ng vÃ¬ nÃ³ giÃºp trÃ¡nh overfitting vÃ  giÃºp mÃ´ hÃ¬nh tá»•ng quÃ¡t hÆ¡n.

ThÆ° viá»‡n sklearn cÃ³ sáºµn GridSearchCV, chÃºng ta cÃ³ thá»ƒ dÃ¹ng nÃ³ Ä‘á»ƒ tá»‘i Æ°u siÃªu tham sá»‘.


**Chuáº©n bá»‹ dá»¯ liá»‡u**

Láº§n nÃ y chÃºng ta sáº½ chia Train vÃ  Test, sau Ä‘Ã³ Ä‘Æ°a Train vÃ o CV
```python
from sklearn.model_selection import GridSearchCV
# fetch dataset 
phishing_websites = fetch_ucirepo(id=327) 
  
# data (as pandas dataframes) 
X = phishing_websites.data.features 
y = phishing_websites.data.targets


# Chia táº­p train vÃ  test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Kiá»ƒm tra kÃ­ch thÆ°á»›c dá»¯ liá»‡u
print(f"Train size: {X_train.shape}, Test size: {X_test.shape}")

```

<pythonoutput>
```
Train size: (8844, 30), Test size: (2211, 30)
```
</pythonoutput>

**Táº¡o mÃ´ hÃ¬nh vÃ  GridSearchCV**

```python
rf = RandomForestClassifier(random_state=42)

# Bá»™ siÃªu tham sá»‘
param_grid = {
    'n_estimators': [50, 100, 200],  
    'max_depth': [3, 5, 10],  
}

# GridSearchCV (cv=5)
grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)
grid_search.fit(X_train, y_train)

# In káº¿t quáº£ tá»‘t nháº¥t
print("Best Parameters:", grid_search.best_params_)
print("Best CV Accuracy:", grid_search.best_score_)
```

<pythonoutput>
```
Best Parameters: {'max_depth': 10, 'n_estimators': 50}
Best CV Accuracy: 0.9538677039716177
```
</pythonoutput>

**ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test**

```python
# Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
y_pred = grid_search.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Tuned Model Accuracy on Test Set: {accuracy:.4f}")
```

<pythonoutput>
```
Tuned Model Accuracy on Test Set: 0.9548
```
</pythonoutput>


CÃ¡c báº¡n cÃ³ thá»ƒ tháº¥y Ä‘á»‘i vá»›i GridSearchCV káº¿t quáº£ dá»± Ä‘oÃ¡n trÃªn táº­p test cÃ³ Ä‘á»™ chÃ­nh xÃ¡c lÃ  `0.9548` , káº¿t quáº£ nÃ y láº¡i tháº¥p hÆ¡n so vá»›i káº¿t quáº£ dá»± Ä‘oÃ¡n trÃªn táº­p test khi dÃ¹ng grid search thá»§ cÃ´ng lÃ  `0.9557`.

Äiá»u nÃ y cÃ³ thá»ƒ do GridSearchCV sá»­ dá»¥ng CV Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c trÃªn nhiá»u táº­p con, do Ä‘Ã³ káº¿t quáº£ trÃªn táº­p test cÃ³ thá»ƒ tháº¥p hÆ¡n. Tuy nhiÃªn, GridSearchCV giÃºp mÃ´ hÃ¬nh á»•n Ä‘á»‹nh hÆ¡n.




